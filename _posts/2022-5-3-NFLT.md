---
layout: post
title: No Free Lunch Theorem (NFLT)
---
## "ê³µì§œ ì ì‹¬ì€ ì—†ë‹¤".

Literally (ë§ ê·¸ëŒ€ë¡œ), "ê³µì§œ ì ì‹¬ì€ ì—†ëŠ” ê²ƒ (No free lunch)" ì„ í†µí•´ "ë¨¸ì‹ ëŸ¬ë‹ì˜ ìµœì í™” (or No general models)"ì™€ì˜ ì—°ê´€ì„±ì„ ë°”ë¡œ ì—°ìƒì‹œí‚¤ê¸°ëŠ” ì–´ë µë‹¤ê³  ìƒê°í•œë‹¤. 
"ê³µì§œ ì ì‹¬" ê³¼ "Machine Learning, Optimization"ì´ ëŒ€ì²´ ë¬´ìŠ¨ ì—°ê´€ì„±ì´ ìˆëŠ” ê±¸ê¹Œ? ê·¸ë˜ì„œ ê³¼ì—°, ë¬´ìŠ¨ ë§ì„ í•˜ê³  ì‹¶ì€ ê±¸ê¹Œ?

ì‹¬ì§€ì–´ Kevin P. Murphyì˜ ã€ŒMachine Learning : A probabilistic Perspective (Chap.1.4.9)ã€ ì—ì„œë„ ì–¸ê¸‰ë˜ì–´ ìˆëŠ”ë°, ì´í•´í•˜ì§€ ëª»í•˜ê³  ê·¸ëƒ¥ ì§€ë‚˜ì¹˜ê¸°ì—ëŠ” ë­”ê°€ ì°œì°œí–ˆê³  ê·¸ë˜ì„œ ë” ì´í•´í•˜ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. 




-----------------------------------------------------------------------

â˜¾ Table of contents

â˜ºï¸ What NFLT exactly means : NFLTëŠ” ë¬´ì—‡ì¼ê¹Œ?

â˜ºï¸ An origin of "No Free Lunch Theorem (NFLT)" : NFLTì˜ ê¸°ì›/ë°°ê²½ì€?

â˜» Reference  

-----------------------------------------------------------------------


## â˜ºï¸ What NFLT exactly means

ìš°ì„ ì€ David Wolpertì™€ William Macreadyê°€ 1997ë…„ ë°œí‘œí•œ ã€ŒNo Free Lunch Theorems for optimizationã€ ì´ë¼ëŠ” ë…¼ë¬¸ì— ì‹¤ë¦° ê²ƒìœ¼ë¡œ 

<u> We have dubbed the associated results "No Free Lunch" theorems because they demonstrate that if an algorithm perfoms well on a certian class of problems then it necessarily pays for that with degraded performance on the set of all remaining problems.</u> 

ì¦‰, ê°„ë‹¨íˆ ë§í•´ **íŠ¹ì • ë¬¸ì œ í˜¹ì€ ë°ì´í„° ì…‹ì— ë§ê²Œ ì˜ ë§Œë“¤ì–´ì§€ê³ , ì§œì—¬ì§€ê³ , ê·¸ë¦¬ê³  ìµœì í™”ëœ "ì•Œê³ ë¦¬ì¦˜, í•´ê²°ì±…, ë°©ë²• ë“±"ì€ ë‹¤ë¥¸ ë¬¸ì œ í˜¹ì€ ë°ì´í„° ì…‹ì—ì„œëŠ” ë§ì§€ ì•ŠëŠ” ë‹¤ëŠ” ê²ƒì„ ìˆ˜í•™ì ìœ¼ë¡œ ì¦ëª…í•œ ì •ë¦¬ì´ë‹¤.** ë”°ë¼ì„œ "ê³µì§œ ì ì‹¬ì€ ì—†ë‹¤"ë¼ëŠ” ë§ì²˜ëŸ¼ ìš°ë¦¬ëŠ” "ì ì‹¬ê°’ì„ ì§€ë¶ˆì„ í•´ì•¼í•œë‹¤"ë¼ê³  í•´ì„ í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ì—¬ê¸°ì„œ "ì ì‹¬ê°’"ì´ë¼ëŠ” ê²ƒì€ ìš°ë¦¬ê°€ í’€ê³ ìí•˜ëŠ” ë¬¸ì œì— ëŒ€í•œ ê°’ì´ë¼ê³  í•´ì„ í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤. 

**ì¦‰, ë…¸ë ¥ì´ë“  ì‹œê°„ì´ë“  ì—´ì •ì´ë“  í˜¹ì€ ì •ë§ ë§ ê·¸ëŒ€ë¡œ "ì•Œê³ ë¦¬ì¦˜, í•´ê²°ì±…, ë°©ë²• ë“±"ì„ ìœ„í•œ ë¹„ìš©ì„ ì§€ë¶ˆ í•´ì•¼ë§Œ í•œë‹¤ëŠ” ê²ƒì´ ì•„ë‹ê¹Œ?**


ê·¸ëŸ¼, Kevin P. Murphyì—ì„œ ì–¸ê¸‰í•œ ë‚´ìš©ì„ í™•ì¸í•´ë³´ì [1].

(í•œê¸€íŒ, ì˜ë¬¸íŒì— ìˆëŠ” ë¬¸êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ì˜€ë‹¤. í•œê¸€íŒì€ ê°œì¸ì†Œì¥ìš©ìœ¼ë¡œ ì§ì ‘ êµ¬ë§¤í•˜ì˜€ë‹¤.)



> [ì˜ë¬¸íŒ]\
All models are wrong, but some models are useful. â€” George Box (Box and Draper 1987)
Much of machine learning is concerned with devising different models, and different algorithms to fit them. We can use methods such as cross validation to empirically choose the best method for our particular problem. However, there is no universally best model â€” this is sometimes called the no free lunch theorem (Wolpert 1996). The reason for this is that a set of assumptions that works well in one domain may work poorly in another.
As a consequence of the no free lunch theorem, we need to develop many different types of models, to cover the wide variety of data that occurs in the real world. And for each model, there may be many different algorithms we can use to train the model, which make different speed-accuracy-complexity tradeoffs. It is this combination of data, models and algorithms that we will be studying in the subsequent chapters.


>[í•œê¸€íŒ]
ëª¨ë“  ëª¨í˜•ì€ ì˜ëª»ëì§€ë§Œ ì¼ë¶€ ëª¨í˜•ì€ ìœ ìš©í•˜ë‹¤. â€” George Box (Box and Draper 1987)

ë¨¸ì‹  ëŸ¬ë‹ì˜ ëŒ€ë¶€ë¶„ì€ ìƒˆë¡œìš´ ëª¨í˜•ì„ ì°½ì•ˆí•˜ê³ , ê·¸ê²ƒë“¤ì„ ì í•©í•˜ê²Œ ë‹¤ë£¨ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ì„ ë§Œë“œëŠ” ê²ƒê³¼ ê´€ë ¨ë¼ ìˆë‹¤. íŠ¹ì • ë¬¸ì œì— ëŒ€í•œ ìµœì ì˜ ê¸°ë²•ì„ ì‹¤í—˜ì ìœ¼ë¡œ ì„ íƒí•˜ê¸° ìœ„í•´ êµì°¨ ê²€ì¦ê³¼ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ëª¨ë“  ë¬¸ì œì— ìµœì ì¸ ë‹¨ í•˜ë‚˜ì˜ ìµœê³  ëª¨í˜•ì€ ì—†ë‹¤. ì´ê²ƒì€ ê³µì§œ ì ì‹¬ì€ ì—†ë‹¤ëŠ” ì´ë¡ ìœ¼ë¡œ ë¶ˆë¦°ë‹¤ (Wolpert 1996). ì´ê²ƒì€ í•˜ë‚˜ì˜ ì˜ì—­ì—ì„œ ì˜ ì‘ë™í•˜ëŠ” ê°€ì •ì´ ë‹¤ë¥¸ ì˜ì—­ì—ì„œ ì˜ëª» ì‘ë™í•˜ëŠ” ê²½ìš°ê°€ ìˆê¸° ë•Œë¬¸ì´ë‹¤. 
ê³µì§œ ì ì‹¬ì´ ì—†ë‹¤ëŠ” ì´ë¡ ì˜ ê²°ê³¼ë¡œ, ì‹¤ì œ ì„¸ê³„ì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•´ì„œ ì—¬ëŸ¬ í˜•íƒœì˜ ëª¨í˜•ì„ ê°œë°œí•´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  ê° ëª¨í˜•ì— ëŒ€í•´ì„œ í›ˆë ¨ì„ ìœ„í•´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ì´ ìˆë‹¤. ì´ëŸ° ì•Œê³ ë¦¬ì¦˜ì€ ì„œë¡œ ë‹¤ë¥¸ ì†ë„-ì •í™•ë„-ë³µì¡ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ê°–ê³  ìˆë‹¤. ì•ìœ¼ë¡œ ì´ëŸ° ë°ì´í„°ì™€ ëª¨í˜•, ì•Œê³ ë¦¬ì¦˜ì˜ ì¡°í•©ì„ ê³µë¶€ í•  ê²ƒì´ë‹¤. 


ê·¸ë¦¬ê³  ì´ëŸ¬í•œ ì•„ë˜ ë§í•˜ëŠ” ë°”ì™€ ê°™ì´, ì´ëŸ¬í•œ NFLTëŠ” Machine learning ê·¸ë¦¬ê³  Optimizationì—ì„œ ë§ì´ ê±°ë¡ ë˜ì§€ë§Œ, ì—¬ì „íˆ ì´í•´í•˜ëŠ”ê²Œ ì–´ë ¤ìš¸ ìˆ˜ ë„ ìˆë‹¤. 



> The ***No Free Lunch Theorem*** is often thrown around in the field of optimization and machine learning, often with little understanding of what it means or implies.
The theorem states that all optimization algorithms perform equally well when their performance is averaged across all possible problems [2].


Okay, ì—¬ê¸°ê¹Œì§€ëŠ” ì–´ë””ì„œë‚˜ ì°¾ì„ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ë¼ê³  ìƒê°í•œë‹¤. 

í•˜ì§€ë§Œ ì—¬ì „íˆ "ê³µì§œ ì ì‹¬"ê³¼ "ë¨¸ì‹ ëŸ¬ë‹"ê³¼ì˜ ì—°ê´€ì„±ì— ëŒ€í•˜ì—¬ 100% ì´í•´ê°€ ë˜ì§€ ì•Šì•˜ë‹¤. 

> ì´ê±´ TMIì´ì§€ë§Œ, ê³µë¶€ë¥¼ í•˜ë‹¤ë³´ë©´ í•­ìƒ í˜¹ì€ ì¢…ì¢… 'Why?' ë¼ëŠ” ë¶€ë¶„ì—ì„œ ë§‰í ë•Œê°€ ìˆë‹¤.
(ê·¸ë˜ì„œ ë‚´ê°€ Physicsë¥¼ ì¢‹ì•„í•˜ì§€ë§Œ, ë‹¤ê°€ê°€ê¸° ë¬´ì²™ ì–´ë ¤ìš´ í•™ë¬¸ì´ë¼ê³  ìƒê°í•œë‹¤)

ë§ˆìŒì€ ê¸‰í•´ì„œ ì´ ì±…ì„ ë‹¤ ëë‚´ì•¼ë§Œ í•˜ëŠ”ë°, ì´ ê²ƒ í•˜ë‚˜ë•Œë¬¸ì— ì§„ë„ë„ ëª»ë‚˜ê°€ê³  êµ‰ì¥íˆ ë‹µë‹µí•˜ì§€ë§Œ ê·¸ë˜ë„ ë°˜ë“œì‹œ ì´í•´ê°€ ìˆ˜ë°˜ë˜ì–´ì•¼ë§Œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆì„ ê²ƒ ê°™ì€ ê³ ì§‘ ì•„ë‹Œ ê³ ì§‘ì„ ë¶€ë¦´ë•Œê°€ ìˆë‹¤. 

ë¬¼ë¡ , ìš°ë¦¬ëŠ” ì´í•´í•  ë¶€ë¶„ì´ ë§ê³ , 'ì´ê²Œ ë­ë¼ê³ ?' í•  ìˆ˜ë„ ìˆì§€ë§Œ, ê·¸ë˜ë„ ë­”ê°€ ì´í•´í•˜ë©´ ë” ê¹Šê²Œ ìƒê°í•  ìˆ˜ ìˆê³ , ë˜ ì˜¤ë˜ ê¸°ì–µ í•  ìˆ˜ë„ ìˆì–´ì„œ ì¡°ê¸ˆ ê³ ì§‘ì„ ë¶€ë¦¬ëŠ” ê²ƒ ê°™ë‹¤. 


## â˜ºï¸ An origin of "No Free Lunch Theorem (NFLT)" 

>Thereâ€™s no free lunch is an American axiom that is well known in economic circles, though its origins seem to be in literature. We will look at the meaning of the admonition thereâ€™s no free lunch, where it came from and some examples of its use in sentences.

>> **The phrase thereâ€™s no free lunch means you donâ€™t get something for nothing, or anything one receives for free will be paid for in another way.**
>> The term comes from a practice in the nineteenth century in the United States, whereby taverns provided a free lunch to drinkers. Obviously, by affording a thrifty lunch of perhaps boiled eggs and peanuts, the bartenders kept paying patrons in their establishments longer, quaffing profitable alcoholic beverages. The term thereâ€™s no free lunch was first used in 1942 by Paul Mallon, an American political  journalist. It was made more popular when the author Robert Heinlein used it in his 1966 novel The Moon is a Harsh Mistress, and then more popular still when it was used by the economist Milton Friedman as the title of his book, Thereâ€™s No Such Thing as a Free Lunch. Some say that the term thereâ€™s no free lunch originated with New Yorker Fiorello La Guardia, elected mayor of New York in 1933, when he said â€œÃˆ finita la cuccagna!â€ This was in regards to the corruption and graft that he intended to clean up. In reality, this phrase is more correctly translated as â€œthe partyâ€™s over!â€ The term thereâ€™s no free lunch is often rendered as thereâ€™s no such thing as a free lunch, there ainâ€™t no such thing as a free lunch or the acronyms TANSTAAFL, TINSTAAFL, and TNSTAAFL [3,4].


**ì¦‰, you donâ€™t get something for nothing, or anything one receives for free will be paid for in another way. ë‹¹ì‹ ì€ ì•„ë¬´ê²ƒë„ ì–»ì§€ ëª»í•˜ê±°ë‚˜ ë¬´ë£Œë¡œë°›ëŠ” ê²ƒì€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§€ë¶ˆí•œë‹¤ë¼ëŠ” ì˜ë¯¸ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.**

ê·¸ë˜ì„œ "ìµœì í™”ëœ ì•Œê³ ë¦¬ì¦˜"ê³¼ì˜ ì—°ê´€ì„±ì— ëŒ€í•˜ì—¬ ë‚´ê°€ í•´ì„ í•œ ë°”ë¡œëŠ”

> ëª¨ë“  ë¬¸ì œì— ì ìš© ê°€ëŠ¥í•œ "ê³µì§œ ì•Œê³ ë¦¬ì¦˜, í•´ê²°ì±…, ë°©ë²• ë“±"ì€ ì—†ë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ê°€ í’€ê³ ì í•˜ëŠ” ë¬¸ì œì— ëŒ€í•œ ì •ì˜, ë°ì´í„°, ì—¬ëŸ¬ ìƒí™©ì— ë”°ë¼ì„œ ê·¸ì— ë§ëŠ” ìµœì í™”ëœ "ì•Œê³ ë¦¬ì¦˜, í•´ê²°ì±…, ë°©ë²• ë“±"ì„ ëª¨ìƒ‰í•´ì•¼ í•œë‹¤. 
ë¼ê³  ìƒê°í•œë‹¤. 

ì¶”ê°€ë¡œ ê¸€ì„ ì½ë‹¤ê°€ **No free lunch**ì˜ ê¸°ì›ì— ëŒ€í•´ì„œ ìƒê°í•œ ë°”ë¥¼ ì ìœ¼ë©´, 19ì„¸ê¸° ì–´ë–¤ ìŒë£Œë¥¼ ë§ˆì‹œë“  free lunchê°€ ì œê³µë˜ì—ˆì§€ë§Œ ê·¸ í›„ ê²½ì œì„±ì¥ ë° ì—¬ëŸ¬ê°€ì§€ ìƒí™©ì´ ë°œìƒí•˜ë©´ì„œ ì´ëŸ¬í•œ ì œê³µì´ ê·¸ë§Œë‘ê²Œ ë˜ë©´ì„œ **No free lunch**ë¼ëŠ” ë§ì´ ë‚˜ì™”ë‹¤ëŠ” ê²ƒì´ë‹¤. ì¦‰, ì–´ë–¤ ìŒë£Œ = ì–´ë–¤ ë¬¸ì œ ë“  free lunch = solution, algorithm, answerì´ ë  ìˆ˜ ì—†ë‹¤ (No)ì´ë‹¤. ì´ëŠ” ì²˜ìŒì— ì–¸ê¸‰ë˜ì—ˆë“¯, **íŠ¹ì • ë¬¸ì œ í˜¹ì€ ë°ì´í„° ì…‹ì— ë§ê²Œ ì˜ ë§Œë“¤ì–´ì§€ê³ , ì§œì—¬ì§€ê³ , ê·¸ë¦¬ê³  ìµœì í™”ëœ "ì•Œê³ ë¦¬ì¦˜, í•´ê²°ì±…, ë°©ë²• ë“±"ì€ ë‹¤ë¥¸ ë¬¸ì œ í˜¹ì€ ë°ì´í„° ì…‹ì—ì„œëŠ” ë§ì§€ ì•ŠëŠ” ë‹¤ëŠ” ê²ƒì„ ìˆ˜í•™ì ìœ¼ë¡œ ì¦ëª…í•œ ì •ë¦¬ì´ë‹¤.** ë¼ê³  í•´ì„ í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤ (050722 update by SS)



ê·¸ë˜ë„ ë­”ê°€ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•˜ë©´ì„œ NFLTì— ëŒ€í•œ ì´í•´ë„ê°€ ë†’ì•„ì§„ ê²ƒ ê°™ì•„ì„œ ì¬ë°Œì—ˆë‹¤. 

ë‚´ê°€ ì´í•´í•œ ê²ƒë“¤ì„ ëˆ„êµ°ê°€ì™€ í•¨ê»˜ ë‚˜ëˆ„ê³ , ëˆ„êµ°ê°€ê°€ ì´í•´í•˜ëŠ”ë° ì¡°ê¸ˆì´ë‚˜ë§ˆ ë„ì›€ì´ ë˜ì—ˆìŒ ì¢‹ê² ë‹¤. 

ë‚˜ ë˜í•œ ëˆ„êµ°ê°€ì—ê²Œ ë„ì›€ì„ ë°›ì•˜ìœ¼ë‹ˆ ë§ì´ë‹¤ :)



## â˜» Reference 
1. https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020
2. https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/
3. https://grammarist.com/phrase/theres-no-free-lunch/
4. https://en.wikipedia.org/wiki/There_ain%27t_no_such_thing_as_a_free_lunch
5. https://towardsdatascience.com/what-no-free-lunch-really-means-in-machine-learning-85493215625d


ğŸŒº **Thanks for reading. Hope to see you again :o)**
