---
layout: post
title: Bayesian Optimization (BO) <img src="/images/B-icon-ver.png" width="30">
---

### Bayesian Optimization (베이지안 최적화) 란?


베이지안 최적화. 어디서부터 시작했는지는 모르겠지만, Gaussian Process Regression (GPR) 을 하다가 어느 순간부터 Bayesian의 세계로 빨려 들어가고 있는 것 같다.   


<p align="center">
<img src="/images/elmo_sliding.gif" width="350">
</p>


요즘은 기존의 나의 공부 방식과는 다소 다르게 의식의 흐름에 따라 공부하고 있는 것 같다. 알다시피 공부 잘하는 학생들은 핵심을 파악하고 그 부분을 공부하는데, 요즘의 나는 그런 것들을 모두 무시하고 의식의 흐름대로 공부하고 있는 것 같지만... 뭐 나름 흥미를 느끼고 있다. 

그래, 🐭 시골쥐의 AI 도시 탐방기라고 여기고 힘차게 시작해보려한다. 


<p align="center">
<img src="/images/Ratatouille_remy.gif" width="350">
</p>


본 글을 작성하기 위해서 다양한 곳에서 정보를 얻었지만, 전반적으로 A tutorial on bayesian Optimization (2018) [1] 이라는 논문을 기반으로 contents를 작성하고자 한다.             


-----------------------------------------------------------------------


우선, Bayesian optimization에 대하여 wikipedia를 검색해보면 [2],


> Bayesian optimization is a sequential design strategy for global optimization of black-box functions that does not assume any functional forms. It is usually employed to optimize expensive-to-evaluate functions.


좀 더 자세한 것을 확인하면 [3], 


> Bayesian Optimization provides a principled technique based on Bayes Theorem to direct a search of a global optimization problem that is efficient and effective. It works by building a probabilistic model of the objective function, called the surrogate function, that is then searched efficiently with an acquisition function before candidate samples are chosen for evaluation on the real objective function.


정리하자면 베이지안 최적화란 목적함수 (objective function, f)를 최대화 혹은 최소화하는 최적해를 찾는 기법으로 베이지안 정리를 기반으로 하고 있다. 또한, 이는 **objective function**과 **acquisition function**이라는 두 개의 큰 요소로 구성되어 있다 [1].


> BayesOpt consists of two main components : a Bayesian statistical model for modeling the objective function, and an acquisition function for deciding where to sample next. 


그런데 일부 글에서는 베이지안의 최적화는 **surrogate model**과 **acquisition function**로 구성되어 있다고 하는데, 둘 다 맞는 말이라고 생각한다. 
이는 **surrogate model**이란 literally **대리(대용) 모델** 로 목적함수인 **objective function**을 추정하는 ML모델이며, 여기서는 **Gaussian Process Regression (GPR)** 을 사용하고 있다. 
따라서 **objective function + surrogate model + acquisition function** 삼총사를 기억하길 바란다.

이외에 베이지안 최적화에 대하여 좀 더 자세한 내용을 이해하기에 앞서 몇가지 키워드를 기억하고 가면 좋을 것 같다. 

~~~~~~~~~~~~~~~~~~~~~
◦ Global optimization
◦ Objective function
◦ Surrogate model 
◦ Acquisition function 
◦ Gaussian Process Regression (GPR) 
◦ Black-box function 
◦ Bayesian Theore
~~~~~~~~~~~~~~~~~~~~~

-----------------------------------------------------------------------

☾ Table of contents

☺︎ Optimization?
  - Global optimization vs Local optimization 
  - Hyperparameter Optimization (HPO) 
 
☺︎ Bayesian Optimization (in short, BO or BayesOpt)    
  - Objective function, f    
  - Surrogate model 
  - Acquisition model 

☻ Reference

-----------------------------------------------------------------------


### ☺︎ Optimization          

Bayesian Optimization을 찾다보면, 심심치않게 glbal optimization과 hyperparameter optimization (HPO)이라는 말을 맞딱뜨리게 된다. 

우선, first things first!!!         

최적화라는 것은 무엇일까? wikipedia의 설명은 다음과 같다 [4,5]


> 최적화(最適化, 영어: mathematical optimization 또는 mathematical programming)는 특정의 집합 위에서 정의된 실수값, 함수, 정수에 대해 그 값이 최대나 최소가 되는 상태를 해석하는 문제이다. 수리 계획 또는 수리 계획 문제라고도 한다. 물리학이나 컴퓨터에서의 최적화 문제는 생각하고 있는 함수를 모델로 한 시스템의 에너지를 나타낸 것으로 여김으로써 에너지 최소화 문제라고도 부른다.



> In mathematics, computer science and economics, an optimization problem is the problem of finding the best solution from all feasible solutions.


뒤에서도 알아둬야 하겠지만, 여기서 짚고 넘어갈 문제는 **최적화**라는 것은 가장 적절한 값 (혹은 someth)을 구하는 것이다. 
여기서 exact solution이 아닌, the best solutoin 구하한다는 표현이 다소 불편할수도 있다. 여기서 불편하다는 표현은 이해가 되지 않는 다는 것이다. 


> 조금 다른 얘기지만, 아시는 분이 미국에서 박사 과정을 할때, 담당 교수님께서 항상 "Do you feel comfortable?" 라고 물어보셨다던데, 그런 맥락으로 생각 할 수 있다. 이해하지 못하면 마음이 굉장히 불편하다 (참을수 없다! 부르르르르르~). 나만 그런가?


<p align="center">
<img src="/images/cant_bear.gif" width="350">
</p>


Anyhow, 최적화라는 말이 너무 general 할수도 있어서 쉽게 와닿지 않는다. 그래서, 우리가 관심있는 ML과 연관지어 생각해보면, **모델이 데이터를 잘 설명할수 있도록 모델 변수들에 관한 목적 함수를 최적화한다** 라고 볼 수 있다. 따라서 여기서 나오는 말이 Hyperparamter optimization (HPO) 이라고 볼수 있을 것 같다. 


> Many algorithms in machine learning optimize an objective function with respect to a set of desired model parameters that control how well a model
explains the data: Finding good parameters can be phrased as an optimization problem. Examples include: (i) linear regression, where we look at curve-fitting problems and optimize linear weight parameters to maximize the likelihood; (ii) neural-network auto-encoders for dimensionality reduction and data compression, where the parameters are the weights and biases of each layer, and where we minimize a reconstruction error by repeated application of the chain rule; and (iii) Gaussian mixture models for modeling data distributions, where we optimize the location and shape parameters of each mixture component to maximize the likelihood of the model [6].


HPO에 대한 설명은 아래서 좀 더 자세히 다루도록 하자. 



#### ☻ Global optimization vs Local optimization 

위에서 Bayesian optimizaiton에 대해서 **Bayesian optimization is a sequential design strategy for global optimization of black-box functions [2]** 이라 했는데, 여기서 Global optimization이라는 것이 무엇인지 알아보고자 한다. 나아가 Global 과 Local 최적화 사이의 차이도 확인하고자 한다. 

우선, Global optimization이란, 


> Global optimization is a branch of applied mathematics and numerical analysis that attempts to find the global minima or maxima of a function or a set of functions on a given set [7]


최적화에서 찾고자 하는 가장 적절한 **최대 혹은 최소** 를 찾는데, global 값을 찾아가는 것이다. Local optimization과 비교해서 확인해보면 


>  Local optimization involves finding the optimal solution for a specific region of the search space, or the global optima for problems with no local optima. Global optimization involves finding the optimal solution on problems that contain local optima. How and when to use local and global search algorithms and how to use both methods in concert [8].

자, Global 과 Local 의 사전적 의미부터 확인하면 다음과 같다 [9].

~~~~~~~~~~~~~~~~~~~~~
◦ Global
  1. 세계적인 
  2. 전반[전체/포괄]적인
◦ Local 
  1. 지역의, 현지의
  2. 일부의
~~~~~~~~~~~~~~~~~~~~~
 
간단한 schematic으로 확인하면 아래와 같다 (아래 schematic은 제가 작성한 것 입니다.).
 
<p align="center">
<img src="/images/Global_vs_Local.jpg" width="600">
</p>

**전반적인 혹은 전체적인** 함수나 값들에서 최적화된 혹은 적절한 혹은 best 최대 혹은 최소를 찾는지 (Global optimization) 아니면 **지역에서 혹은 일부의** 함수나 값들에서 최적화된 혹은 적절한 혹은 best 최대 혹은 최소를 찾는지 (Local optimization)에 따라 나눠진다고 볼 수 있다. 

우선은 이정도의 개념만 갖고 가보도록 하자. 


#### ☻ Hyperparameter Optimization (HPO)

ML/DL에서 사용되는 optimization은 **학습을 수행하기 사전에 설정하는 hyperparameter의 최적값 탐색하는 문제** 에 사용된다. 

우선, Hyperparameter에 대해 알아보자면, 이는 learning 시작하기 전에 미리 정하는 값이다. 모델로 learning하는 값이 아니라 training전 사전에 설정해서 주어지는 값으로 최적의 모델을 구하기 위해서 tuning을 해줄 필요가 있다. 따라서, Hyperparamter tuning이라는 하는 것이다.


> Hyperparameters refer to the parameters that the model cannot learn and need to be provided before training. Hyperparameter tuning basically refers to tweaking the parameters of the model, which is basically a lengthy process [10].


여기서, 좀 더 deep dive하게 확인해서, paramter앞에 Hyper-라는 말을 붙은 이유에 대해서 좀 더 자세히 살펴보자면, 


> Hyperparameters are parameters whose values control the learning process and determine the values of model parameters that a learning algorithm ends up learning. The prefix ‘hyper_’ suggests that they are ‘top-level’ parameters that control the learning process and the model parameters that result from it. As a machine learning engineer designing a model, you choose and set hyperparameter values that your learning algorithm will use before the training of the model even begins. In this light, hyperparameters are said to be external to the model because the model cannot change its values during learning/training [11].


> hyperparameters that the learning algorithm will use to learn the optimal parameters that correctly map the input features (independent variables) to the labels or targets (dependent variable) such that you achieve some form of intelligence[11].


즉, learning proecss와 모델의 변수들을 제어하는 top-level의 변수라서 hyper-가 붙는 것이다. Hyper-의 사전적 의미를 확인하면 아래와 같고, top-level이라는 말과 상통한다 [12].

~~~~~~~~~~~~~~~~~~~~~
◦ hyper
  1. above, beyond, SUPER-
  2. excessively, excessive
~~~~~~~~~~~~~~~~~~~~~

따라서 최적의 hyperparamter를 제공해주는 것이 최적의 model을 구현하는데 중요하다고 볼 수 있다. 

이러한 HPO에는 여러가지 방법이 있다 [10]. 

~~~~~~~~~~~~~~~~~~~~~
◦ Manual search grid 
◦ Grid search 
◦ Random search (Randomized Search)
◦ HyperOpt-Sklearn
◦ Bayesian optimiation 
◦ Evolution algorithm
~~~~~~~~~~~~~~~~~~~~~

각각의 방법들에 대한 설명은 out of our scope이라서 더 이상 다루지 않고, 바로 Bayesian optimization으로 넘어가도록 한다. 


### ☺︎ Bayesian Optimization  

베이지안 최적화란 베이지안 정리를 기반으로, **objective function (목적함수)** 를 추정하는 확률 기반의 **surrogate model**과 **acquisition function**이라는 두 개의 큰 요소로 구성되어 있다 [1].

> BayesOpt consists of two main components : a Bayesian statistical model for modeling the objective function, and an acquisition function for deciding where to sample next. 

최적화하는 과정은 아래와 같고 [13].

> Since the objective function is unknown, the Bayesian strategy is to treat it as a random function and place a prior over it. The prior captures beliefs about the behavior of the function. After gathering the function evaluations, which are treated as data, the prior is updated to form the posterior distribution over the objective function. The posterior distribution, in turn, is used to construct an acquisition function (often also referred to as infill sampling criteria) that determines the next query point.

과정을 Pseudo-code로 본다면 아래와 같다 (아래 Pseudo-code는 논문 [14]에서 갖고와서 인용하였습니다.).

<p align="center">
<img src="/images/Pseudo_code_BO.png" width="450">
</p>
Fig. Pseudo-code of BO [14]

코드에서 5번인 statistical model은 surrogate model, 즉 GPR이라고 볼 수 있다. 

이러한 과정을 schematic으로 확인하면 좀 더 직관적으로 이해할 수 있다(아래 Schematic of BO는 논문[14]의 Fig.1이며, BO의 설명을 위해서 갖고와서 인용하였습니다.).

<p align="center">
<img src="/images/Schematic_BO.png" width="600">
</p>
Fig. Schematic of BO [14]

조금 더 이해를 쉽게 하기 위해 작은 petit schematic을 그려보았다 (아래 schematic은 위의 그림 일부에 내용을 추가해서 작성한 것 입니다.).


<p align="center">
<img src="/images/Schematic_BO_SS.jpg" width="750">
</p>
Fig. Schematic of BO w/ comments by SS


GPR을 기반으로 하고 있는 surrogate model에서 mean과 variance를 구하고, 그 값을 acquisition function에 적용해서 next p't를 찾아냄에 따라 data augmentation이 되어 간다. 그리고 이 늘어난 데이터를 기반으로 또 GPR를 함에  최적의 objective function을 찾아가는 과정이 Bayesian Optimization이라고 할 수 있다. 



#### ☻ Objective function, f

objective function은 목적함수로 베이지안 최적화에서는 이 함수를 최적화하는 것이 중요하다. 이러한  objective function의 특징으로는 다음과 같다[1,13].  

~~~~~~~~~~~~~~~~~~~~~
◦ Continuous 
◦ Expensive to evaluate 
◦ Black-box (unknown struction) 
◦ derivative free : prevents the application of first- and  second-order methods 
◦ noise-free : be observed w/o noise
◦ nonlinear 
◦ non-convex function
◦ global optimum
~~~~~~~~~~~~~~~~~~~~~

그래서 간단하게 한문장으로 정리하자면, 


> We summarize these problem characteristics by saying that BayesOpt is designed for black-box derivative-free global optimization [1]. 


여기서 objective를 black-box라고 하는 이유는 어떠한 형태인지, derivative되는지 등 아무것도 모르는 black-box의 상태로 존재하며, input으로 x가 들어가서 output으로 f(x)가 나온다는 것만 알고 있기 때문이다.(아래 schematic은 제가 작성한 것 입니다.).

<p align="center">
<img src="/images/black_box.jpg" width="600">
</p>

이러한 objective function을 구하는 것이 우리의 quest이며, 이때 사용되는 것이 이제 살펴볼 surrogate model이다. 

#### ☻ Surrogate model 

surrogate  model은 blackbox function을 위한 statistic/probabilistic 모델링으로, 미지의 목적함수 objective function을 확률적으로 추정하는 모델이라고 볼 수 있다.

surrogate의 사전적 의미를 확인해보면 **대리의, 대용의**라는 의미를 포함하고 있다 [15]. 

~~~~~~~~~~~~~~~~~~~~~
◦ surrogate
  : someone or something that replaces or is used instead of someone or something else; a substitute for another
~~~~~~~~~~~~~~~~~~~~~


> A surrogate model is an engineering method used when an outcome of interest cannot be easily measured or computed, so a model of the outcome is used instead. Most engineering design problems require experiments and/or simulations to evaluate design objective and constraint functions as a function of design variables [16]. 


ML관점에서 surrogate model을 확인하면 아래와 같다 [17]. 


> 복잡하고 설명하기 힘든 모형(블랙박스 모형)을 단순하고 설명하기 쉬운 모형(대리 모형)으로 대신 설명하는 방법을 말한다. 선형회귀 모형, 로지스틱 회귀모형, 트리모형 등의 설명 가능한 모형을 대리 모형으로 사용할 수 있다. 대리 모형은 학습시키는 방식에 따라 크게 두 가지 방향으로 분류해 볼 수 있다. train 데이터의 전부 또는 일부를 대리 모형으로 다시 학습하여 사용하는 방법을 전역적 대리 모형(global surrogate model)이라 하고, 특정 데이터 포인트 근방에서 샘플링된 데이터를 활용하여 대리 모형을 학습하여 사용하는 방법을 국소적 대리 모형(local surrogate model)이라고 한다.


따라서 black-box인 objective function을 설명하기위해 고려한 것이 surrogate model (대리모형)이라고 볼 수 있고, 우리는 Bayes Theorem을 기반으로 하고 있는 GPR을 사용하게 됨에 따라 본 최적화 방법이 **Bayesian Optimization**이 되는 것이다. 

휴~ 이제서야 조금 이해가 되는 것 같다...아주 조금? 

<p align="center">
<img src="/images/Ratatouille_remy_whatever.gif" width="350">
</p>


자, 다시 논문으로 돌아가서 확인하면 [1,18]







**working here**






즉, 현재까지 avaialable data인 D ={(x1,y1)... (xn,yn)}를 갖고 f(x)를 구하는 것이다. 여기서는 Gaussian Process Regression (GPR)을 이용해서 mean과 covariance를 구하고, 이 값들을 aquisition function에 업데이트 시켜준다. 

#### ☻ Acquisition function

다음 테스트 시 고려한 데이터 추천하는데 활용하는 함수, 탐색할 입력값 후보 추천하는 함수로 surrogate model에서 준 mean과 variance 값을 이용하고 있다. 이때,  agquisitoin function의 역할은 exploition과 exploration의 balance를 잘 맞추는 것이 중요하다. 


<p align="center">
<img src="/images/sesame_what.gif" width="350">
</p>



> They all trade-off exploration and exploitation so as to minimize the number of function queries [13]. 


언급하였듯이 exploitation 과 exploration은 trade off관계로 **exploitation은 우리가 알고 있는 영역** 그리고 **exploration은 우리가 잘 모르는 영역** 을 의미한다 [19].


> Exploration ensures the algorithm to reach different promising regions of the search space, whereas exploitation ensures the searching of optimal solutions within the given region. The fine tuning of these components is required to achieve the optimal solution for a given problem. It is difficult to balance between these components due to stochastic nature of optimization problem. This fact motivates us to develop a novel metaheuristic algorithm for solving real-life engineering design problem. The performance of one optimizer to solve the set of problem does not guarantee to solve all optimization problems with different natures.

이러한 설명은 너무 general해서 우리가 고려하는 Acquisition function에서 사용되는 exploitation과 exploration에 대해서 확인하면 아래와 같고, 이 둘의 balance를 잘 유지하면서 next query p't를 찾아주는 것이 acquisition function의 역할이라 할 수 있다 [20,21]. 

~~~~~~~~~~~~~~~~~~~~~
◦ Exploitation : posterial mean 이 높은 영역 
◦ Exploration :  posterial variance가 높은 영역 
~~~~~~~~~~~~~~~~~~~~~


> Choose the next x where the posterior mean is hight (exploitation) and the posterior variance is high (exploration). 


> Comparing two points x1 and x2: if their means are the same, then BO will pick the one that has larger σ2(x). This is called exploration.Comparing two points x1 and x2: if their variances are the same, then BO will pick the one that has larger μ(x). This is called exploitation [21].


이러한 Acquisitoin functions으로는 아래와 같이 다양한 방법이 있다 [1].

~~~~~~~~~~~~~~~~~~~~~
◦ Probability of Improvement (PI)
◦ Expected Improvement (EI)
◦ Bayesian expeced losses
◦ Upper confindence bouncds (UCB)
◦ Thompson smapling 
◦ GP Upper Con dence Bound (GP-UCB)
◦ Entropy search 
◦ Knowledge gradient 
~~~~~~~~~~~~~~~~~~~~~


여기서 우리가 고려한 function은 EI이고, 이러한 배경으로는 EI가 사용하기 편하고 perform well하기 때문이다. 각 function에 대한 자세한 내용은 out of scope이라서 생략하기로 한다 [1,13]. 


**working here**





오호! 이제 Bo (BayesOpt)에 대해서 좀 이해가 되는 것 같다. **Bayes theorem** 과 **Optimization** 의 만남이란 환상적이구나~~


<p align="center">
<img src="/images/Ratatouille_remy_happy.gif" width="350">
</p>


-----------------------------------------------------------------------

글을 작성한다는 것은 내가 배운 것을 공유한다는 관점에서는 재밌고 뿌듯함을 느낀다. 하지만 한편으로는 무척이나 조심스럽고 큰 책임감을 느낀다.

모든 일에는 책임감이 따르기 마련이니 수정할 부분이 있다면 추후에도 계속 업데이트할 예정이다. 

공부해야 할 것도 많고, 배우고 싶은 것들도 많고, 갈 길도 좀 멀지만 그래도 조금씩 그리고 꾸준히 나아가보자 한다. 

<p align="center">
<img src="/images/elmo_workingout.gif" width="350">
</p>


### ☻ Reference
1. [Paper : A Tutorial on Bayesian Optimization](https://arxiv.org/abs/1807.02811)
2. [wikipedia : Bayesian Optimization](https://en.wikipedia.org/wiki/Bayesian_optimization)
3. [Machine Learning Mastery : How to Implement Bayesian Optimization from Scratch in Python](https://machinelearningmastery.com/what-is-bayesian-optimization/)
4. wikipedia : 수학적 최적화
5. [wikipedia : Optimization problem](https://en.wikipedia.org/wiki/Optimization_problem)
6. [Book (개인 소장): Mathematics for Machine Learning by Book by A. Aldo Faisal, Cheng Soon Ong, and Marc Peter Deisenroth](https://www.amazon.com/Mathematics-Machine-Learning-Peter-Deisenroth/dp/110845514X)  
7. [wikipedia : Global optimization](https://en.wikipedia.org/wiki/Global_optimization)
8. [Machine Learning Mastery : Local Optimization versus Global Optimization](https://machinelearningmastery.com/local-optimization-versus-global-optimization/#:~:text=Local%20optimization%20involves%20finding%20the,problems%20that%20contain%20local%20optima)
9. 네이버 국어/영어사전
10. [7 Hyperparameter Optimization Techniques Every Data Scientist Should Know](https://towardsdatascience.com/7-hyperparameter-optimization-techniques-every-data-scientist-should-know-12cdebe713da)
11. [Parameters and Hyperparameters in Machine Learning and Deep Learning](https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac)
12. [Definition of hyper-](https://www.merriam-webster.com/dictionary/hyper)
13. [wikipedia : Bayesian Optimization](https://en.wikipedia.org/wiki/Bayesian_optimization#:~:text=Bayesian%20optimization%20is%20a%20sequential,expensive%2Dto%2Devaluate%20functions)
14. [Paper :Taking the Human Out of the Loop: A Review of Bayesian Optimization (2016)](https://ieeexplore.ieee.org/document/7352306)
15. [cambridge dictionary : surrogate](https://dictionary.cambridge.org/dictionary/english/surrogate)
16. [wikipedia : surrogate model](https://en.wikipedia.org/wiki/Surrogate_model#:~:text=A%20surrogate%20model%20is%20an,a%20function%20of%20design%20variables.)
17. [대리모형](https://psystat.tistory.com/139)
18. [논문리뷰:베이지안 최적화 (Bayesian Optimization)](https://gils-lab.tistory.com/61)
19. [What is Exploitation and Exploration in Optimization Algorithms?](https://www.researchgate.net/post/What_is_Exploitation_and_Exploration_in_Optimization_Algorithms#:~:text=Exploration%20ensures%20the%20algorithm%20to,solution%20for%20a%20given%20problem)
20. [Epxloration and Exploitation](https://wonwooddo.tistory.com/89)
21. [How does Bayesian Optimization balance exploration with exploitation?](https://stats.stackexchange.com/questions/509812/how-does-bayesian-optimization-balance-exploration-with-exploitation)

Code : [베이지안 최적화](https://notebook.community/zzsza/TIL/python/bayesian-optimization)

### ☻ image sources
1. [Giphy](https://giphy.com/search/sesame-street)


🌺 **Thanks for reading. Hope to see you again :o)**


-----------------------------------


<p align="center">
<img src="/images/B-icon-ver.png" width="150">
</p>

모두의 연구소에서 진행하는 "함께 콘텐츠를 제작하는 콘텐츠 크리에이터 모임"인 **COCRE(코크리)** 의 2기 회원으로 제작한 글입니다

[🐘 코크리가 궁금하다면 클릭!](https://medium.com/modulabs/cocre-%EC%BD%94%ED%81%AC%EB%A6%AC-%EB%A5%BC-%EC%86%8C%EA%B0%9C%ED%95%A9%EB%8B%88%EB%8B%A4-c3a4e9519e85)




