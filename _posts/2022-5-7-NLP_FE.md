---
layout: post
title: Feature Engineering & Preprocessing for NLP
---



Before we consider diverse models to predict, pretty clean and well-organized ingredients, we are going to call **feataures**, should be well-prepared. 
Here, preprocessing and **Feature engineering** will be covered but these process are limited in NLP field. (Ofc, these concepts could be applied to fields.)

First things first, we should **Natural Language Process** is. ~~

but it is quite tricky and time consuming process to be read by the computer. 


-----------------------------------------------------------------------

☾ Table of contents

☺︎ Preprocessing              
  - tokenization         
  - remove stop words         
  - stemming           
  - POS tagging         
  - Lemmatization             
  - language detection          
☺︎ Feature extraction            
  - weighted words - BOW          
  - countvectorizer          
  - TF-IDF          
☺︎ Embedding          
  - word2vec -> gensim          
  - Glove          
  - FastText          
☺︎ Feature Selection                      
☺︎ What the next step is?          
☻ Reference
          
-----------------------------------------------------------------------


### ☺︎ Preprocessing 
          

#### ☻ 

**sample**

![\Large \sqrt{\frac{n}{6}}](https://latex.codecogs.com/svg.image?%5Csqrt%7B%5Cfrac%7Bn%7D%7B6%7D%7D)
<!-- https://www.codecogs.com/latex/eqneditor.php -->

![Fig02](/images/DR_Fig02.png)
Ref [3]

### ☺︎ Feature extraction 


### ☺︎ Embedding 


### ☺︎ Feature selection 


### ☺︎ Next steps?


### ☻ Reference
1. [book, 개인 소장] Hands-on Machine laerning with Scikit-Learn Keras & TensorFlow : 핸즈온 머신러닝 2판
3. [book, 개인 소장] Machine Learning: An Algorithmic Perspective by Stephen Marsland
4. 


🌺 **Thanks for reading. Hope to see you again :o)**
